{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14b06d5c-325f-4db3-bd49-9b555c58fc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import json\n",
    "import collections\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    " \n",
    "sys.setrecursionlimit(5000) \n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eff35d8d-2f84-4631-bfa9-a3349d736860",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_data(Data.Dataset):\n",
    "    def __init__(self,max_len=50,min_en_count=0,min_cn_count=0):\n",
    "        self.max_len = max_len\n",
    "        self.min_en_count = min_en_count\n",
    "        self.min_cn_count = min_cn_count\n",
    "        self.counter = None\n",
    "        self.cn_itos = ['<SOS>','<EOS>','<UNK>']\n",
    "        self.cn_stoi = {'<SOS>':0,'<EOS>':1,'<UNK>':2}\n",
    "        self.cn_data = []\n",
    "        self.en_itos = ['<SOS>','<EOS>','<UNK>']\n",
    "        self.en_stoi = {'<SOS>':0,'<EOS>':1,'<UNK>':2}\n",
    "        self.en_data = []\n",
    "        self.num_cn_vocab = 3\n",
    "        self.num_en_vocab = 3\n",
    "        self.len = 0\n",
    "        \n",
    "    def get_raw_data_cn_en(self,file,js=False, divide=1, choose=1):\n",
    "        all_cn = []\n",
    "        all_en = []\n",
    "        if js == False:\n",
    "            with open(file) as f:\n",
    "                lines = f.readlines()\n",
    "                data_len = len(lines)\n",
    "                k = int(data_len//divide)\n",
    "                start = max((choose-1)*k,0)\n",
    "                end = min(choose*k,data_len)\n",
    "                for line in lines[start:end]:\n",
    "                    cn,en = line.strip().split('\\t')\n",
    "                    en = en.lower()\n",
    "                    en = re.sub(r\"([,'.!?])\", r\" \\1\", en)\n",
    "                    en = re.sub(r\"[^a-zA-Z\\u4e00-\\u9fa5.,'!?]+\", r\" \", en)\n",
    "#                     cn = re.sub(r\"([.!?])\", r\" \\1\", cn)\n",
    "                    cn = re.sub(r\"[^a-zA-Z\\u4e00-\\u9fa5.,'‘’“”!?，。？！]+\", r\" \", cn)\n",
    "                    en=en.split()\n",
    "                    all_cn.append(cn)\n",
    "                    all_en.append(en)\n",
    "        if js == True:\n",
    "            with open(file) as f:\n",
    "                lines = f.readlines()\n",
    "                data_len = len(lines)\n",
    "                k = int(data_len//divide)\n",
    "                start = max((choose-1)*k,0)\n",
    "                end = min(choose*k,data_len)\n",
    "                for line in lines[start:end]:\n",
    "                    st = json.loads(line)\n",
    "                    cn = st['chinese']\n",
    "                    en = st['english'].lower()\n",
    "                    en = re.sub(r\"([,'.!?])\", r\" \\1\", en)\n",
    "                    en = re.sub(r\"[^a-zA-Z\\u4e00-\\u9fa5.,'!?]+\", r\" \", en)\n",
    "#                     cn = re.sub(r\"([.!?])\", r\" \\1\", cn)\n",
    "                    cn = re.sub(r\"[^a-zA-Z\\u4e00-\\u9fa5.,'‘’“”!?，。？！]+\", r\" \", cn)\n",
    "                    en=en.split()\n",
    "                    all_cn.append(cn)\n",
    "                    all_en.append(en)\n",
    "        return all_cn,all_en\n",
    "    \n",
    "    def get_cn_en_stoi_itos(self,raw_cn,raw_en):\n",
    "        cnCounter = collections.Counter([tk for line in raw_cn for tk in line])\n",
    "        enCounter = collections.Counter([tk for line in raw_en for tk in line])\n",
    "        cnCounter = dict(filter(lambda x: x[1]>=self.min_cn_count,cnCounter.most_common()))\n",
    "        enCounter = dict(filter(lambda x: x[1]>=self.min_en_count,enCounter.most_common()))\n",
    "        \n",
    "        for tk,_ in cnCounter.items():\n",
    "            self.cn_itos.append(tk)\n",
    "        for tk,_ in enCounter.items():\n",
    "            self.en_itos.append(tk)\n",
    "        \n",
    "        self.cn_stoi = {tk:idx for idx,tk in enumerate(self.cn_itos)}\n",
    "        self.en_stoi = {tk:idx for idx,tk in enumerate(self.en_itos)}\n",
    "        \n",
    "        self.num_cn_vocab = len(self.cn_stoi)\n",
    "        self.num_en_vocab = len(self.en_stoi)\n",
    "        \n",
    "    def get_from_vocab(self,cn_file,en_file):\n",
    "        self.cn_itos = []\n",
    "        self.en_itos = []\n",
    "        \n",
    "        with open(cn_file) as f:\n",
    "            for line in f.readlines():\n",
    "                self.cn_itos.append(line.replace('\\n',''))\n",
    "        with open(en_file) as f:\n",
    "            for line in f.readlines():\n",
    "                self.en_itos.append(line.replace('\\n',''))\n",
    "        \n",
    "        self.cn_stoi = {tk: idx for idx,tk in enumerate(self.cn_itos)}\n",
    "        self.en_stoi = {tk: idx for idx,tk in enumerate(self.en_itos)}\n",
    "        \n",
    "        self.num_cn_vocab = len(self.cn_stoi)\n",
    "        self.num_en_vocab = len(self.en_stoi)\n",
    "                \n",
    "        \n",
    "    def get_data(self,raw_cn,raw_en):\n",
    "        self.cn_data = []\n",
    "        self.en_data = []\n",
    "        k = [0]*len(raw_cn)\n",
    "        for idx,line in enumerate(raw_cn):\n",
    "            if len(line) > self.max_len:\n",
    "                k[idx] = 1\n",
    "                continue\n",
    "            temp = []\n",
    "            temp.append(0)\n",
    "            for tk in line:\n",
    "                if tk not in self.cn_itos:\n",
    "                    tk = '<UNK>'\n",
    "                temp.append(self.cn_stoi[tk])\n",
    "            temp.append(1)\n",
    "            self.cn_data.append(temp)\n",
    "            \n",
    "        for idx,line in enumerate(raw_en):\n",
    "            if k[idx] == 1:\n",
    "                continue\n",
    "            temp = []\n",
    "            temp.append(0)\n",
    "            for tk in line:\n",
    "                if tk not in self.en_itos:\n",
    "                    tk = '<UNK>'\n",
    "                temp.append(self.en_stoi[tk])\n",
    "            temp.append(1)\n",
    "            self.en_data.append(temp)\n",
    "        self.len = len(self.cn_data)\n",
    "        \n",
    "    def append_data(self,raw_cn,raw_en):\n",
    "        k = [0]*len(raw_cn)\n",
    "        for idx,line in enumerate(raw_cn):\n",
    "            if len(line) > self.max_len:\n",
    "                k[idx] = 1\n",
    "                continue\n",
    "            temp = []\n",
    "            temp.append(0)\n",
    "            for tk in line:\n",
    "                if tk not in self.cn_itos:\n",
    "                    tk = '<UNK>'\n",
    "                temp.append(self.cn_stoi[tk])\n",
    "            temp.append(1)\n",
    "            self.cn_data.append(temp)\n",
    "            \n",
    "        for idx,line in enumerate(raw_en):\n",
    "            if k[idx] == 1:\n",
    "                continue\n",
    "            temp = []\n",
    "            temp.append(0)\n",
    "            for tk in line:\n",
    "                if tk not in self.en_itos:\n",
    "                    tk = '<UNK>'\n",
    "                temp.append(self.en_stoi[tk])\n",
    "            temp.append(1)\n",
    "            self.en_data.append(temp)\n",
    "        self.len = len(self.cn_data)\n",
    "        \n",
    "    def do_all(self,file,js=False):\n",
    "        cn,en = self.get_raw_data_cn_en(file=file,js=js)\n",
    "        self.get_cn_en_stoi_itos(cn,en)\n",
    "        self.get_data(cn,en)\n",
    "        \n",
    "    \n",
    "    def get_data_pair(self,idx):\n",
    "        return self.cn_data[idx],self.en_data[idx]\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.get_data_pair(idx)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b091569-57e6-4b03-b751-24ca11ed54f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(data):\n",
    "    src_max_len = max(len(src) for src,_ in data)\n",
    "    tgt_max_len = max(len(tgt) for _,tgt in data)\n",
    "    src, tgt1, tgt2, s_mask, t_mask, loss_mask= [],[],[],[],[],[]\n",
    "    \n",
    "    for s, t in data:\n",
    "        slen = len(s)\n",
    "        tlen = len(t)\n",
    "        s1 = s + [0]*(src_max_len-slen)\n",
    "        t1 = t[:-1] + [0]*(tgt_max_len-tlen)\n",
    "        t2 = t[1:] + [0]*(tgt_max_len-tlen)\n",
    "        s1_mask = [0]*slen + [1]*(src_max_len-slen)\n",
    "        t1_mask = [0]*(tlen-1) + [1]*(tgt_max_len-tlen)\n",
    "        loss1_mask = [1]*(tlen-1) + [0]*(tgt_max_len-tlen)\n",
    "        src.append(s1)\n",
    "        tgt1.append(t1)\n",
    "        tgt2.append(t2)\n",
    "        s_mask.append(s1_mask)\n",
    "        t_mask.append(t1_mask)\n",
    "        loss_mask.append(loss1_mask)\n",
    "    \n",
    "    return (torch.tensor(src).long(),\n",
    "            torch.tensor(tgt1).long(),\n",
    "            torch.tensor(tgt2).long(),\n",
    "            torch.tensor(s_mask).float(),\n",
    "            torch.tensor(t_mask).float(),\n",
    "            torch.tensor(loss_mask).float())\n",
    "\n",
    "# data_iter = Data.DataLoader(dataset,batch_size,shuffle=True,collate_fn=batchify)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c03c0aa-215e-405a-8625-d627543257d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Warmup:\n",
    "    def __init__(self,optimizer_w, warmup_step,d_model,step_size=1,last_epoch=-1,verbose=False):\n",
    "        self.lambda1 = lambda epoch_w: math.pow(d_model+1e-10,-0.5)*min(math.pow(epoch_w+1e-10,-0.5),epoch_w*math.pow(warmup_step+1e-10,-1.5))\n",
    "        self.scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer_w,lr_lambda=self.lambda1,\n",
    "                                                          last_epoch=last_epoch, verbose=verbose)\n",
    "    \n",
    "    def step(self):\n",
    "        self.scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4c70336-e548-4d04-859b-f418a4a3b263",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_2(nn.Module):\n",
    "    def __init__(self,num_vocab,d_model=512,nhead=2,num_layers=2,dropout=0.1):\n",
    "        super(Encoder_2,self).__init__()\n",
    "        self.embedding = nn.Embedding(num_vocab,d_model)\n",
    "        self.MH = nn.TransformerEncoderLayer(d_model=d_model,nhead=nhead,dropout=dropout)\n",
    "        self.all_MH = nn.TransformerEncoder(self.MH,num_layers)\n",
    "        self.position_embedding = self.get_position_embedding(d_model,100).to(device)\n",
    "                                       \n",
    "    def forward(self,myinput,mask=None):\n",
    "        X = self.embedding(myinput)\n",
    "        X += self.position_embedding[:X.shape[1]]\n",
    "        X = X.permute(1,0,2)\n",
    "        #X shaep(L, Batch_size, d_model)\n",
    "        out = self.all_MH(X,src_key_padding_mask=mask)\n",
    "        return out\n",
    "    \n",
    "    def get_position_embedding(self,d_model,max_len):\n",
    "        table = torch.empty(max_len,d_model)\n",
    "        for position in range(max_len):\n",
    "            for i in range(d_model):\n",
    "                table[position,i] = position/10000**(i/d_model)\n",
    "        table[:,0::2] = torch.sin(table[:,0::2])\n",
    "        table[:,1::2] = torch.sin(table[:,1::2])\n",
    "        return table.float()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52970333-6afe-44c4-84bd-2ba1285eb8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder_2(nn.Module):\n",
    "    def __init__(self,num_vocab,d_model=512,nhead=2,num_layers=2,dropout=0.1):\n",
    "        super(Decoder_2,self).__init__()\n",
    "        self.num_vocab = num_vocab\n",
    "        self.embedding = nn.Embedding(num_vocab, d_model)\n",
    "        self.MH = nn.TransformerDecoderLayer(d_model=d_model,nhead=nhead,dropout=dropout)\n",
    "        self.all_MH = nn.TransformerDecoder(self.MH,num_layers)\n",
    "        self.dense = nn.Linear(d_model,num_vocab)\n",
    "        self.position_embedding = self.get_position_embedding(d_model,100).to(device)\n",
    "        \n",
    "    def forward(self,target,memory,t_mask=None,m_mask=None,tgt_mask=None):\n",
    "        X = self.embedding(target)\n",
    "        X += self.position_embedding[:X.shape[1]]\n",
    "        X = X.permute(1,0,2)\n",
    "        Y = self.all_MH(X,memory,tgt_key_padding_mask=t_mask,memory_key_padding_mask=m_mask,tgt_mask=tgt_mask)\n",
    "        out = self.dense(Y.permute(1,0,2))\n",
    "        return out\n",
    "    \n",
    "    def get_position_embedding(self,d_model,max_len):\n",
    "        table = torch.empty(max_len,d_model)\n",
    "        for position in range(max_len):\n",
    "            for i in range(d_model):\n",
    "                table[position,i] = position/10000**(i/d_model)\n",
    "        table[:,0::2] = torch.sin(table[:,0::2])\n",
    "        table[:,1::2] = torch.sin(table[:,1::2])\n",
    "        return table.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaa9b4a9-1fa3-42ca-aeed-c967fb1bf713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decoder_mask(L):\n",
    "    return torch.from_numpy(np.triu(np.ones(L),k=1)).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9aef66c0-7da3-41df-8324-eda0664b30e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Myplot:\n",
    "    def __init__(self,step_size=10):\n",
    "        self.all_loss = []\n",
    "        self.cum_loss = 0\n",
    "        self.step = 0\n",
    "        self.step_size = step_size\n",
    "        \n",
    "    def forward(self,loss):\n",
    "        self.cum_loss += loss\n",
    "        self.step += 1\n",
    "        if self.step%self.step_size == 0:\n",
    "            self.all_loss.append(self.cum_loss/self.step)\n",
    "            self.cum_loss = 0\n",
    "            self.step = 0\n",
    "            \n",
    "    def show(self):\n",
    "        import matplotlib.pyplot as plt\n",
    "        import matplotlib.ticker as ticker\n",
    "        import numpy as np\n",
    "        plt.figure()\n",
    "        fig, ax = plt.subplots()\n",
    "        loc = ticker.MultipleLocator(base=0.2) # put ticks at regular intervals\n",
    "        ax.yaxis.set_major_locator(loc)\n",
    "        plt.plot(self.all_loss)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cae01f71-5be5-4b60-9143-0c07730eabd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs,encoder,decoder,en_optim,de_optim,en_scheduler,de_scheduler,\n",
    "          criterion,train_iter,myplt,teacher_force_ratio=0.9,clip=5):\n",
    "    \n",
    "    import time \n",
    "    \n",
    "    start = time.time()\n",
    "    per_n_steps = 300\n",
    "    steps = 0\n",
    "    arang_list = torch.arange(512)\n",
    "    ones_list = torch.ones(512)\n",
    "    \n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    \n",
    "    for epoch in range(1,num_epochs+1):\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        sum_loss = 0\n",
    "        k = 0\n",
    "        \n",
    "        for src, tgt1, tgt2, s_mask, t_mask, loss_mask in train_iter:\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            steps += 1\n",
    "            \n",
    "            src = src.to(device)\n",
    "            tgt1 = tgt1.to(device)\n",
    "            tgt2 = tgt2.to(device)\n",
    "            s_mask = s_mask.to(device)\n",
    "            t_mask = t_mask.to(device)\n",
    "\n",
    "            #else do tecacher_forcing\n",
    "            changes = random.choices(arang_list[1:tgt1.shape[-1]],ones_list[1:tgt1.shape[-1]],k=int(tgt1.shape[-1]*(1-teacher_force_ratio)))\n",
    "            for idx in changes:\n",
    "                tgt1[:,idx] = random.randint(3,decoder.num_vocab-1)\n",
    "                    \n",
    "                \n",
    "            \n",
    "            en_scheduler.step()\n",
    "            de_scheduler.step()\n",
    "            en_optim.zero_grad()\n",
    "            de_optim.zero_grad()\n",
    "            memory = encoder(src,s_mask)\n",
    "            tgt_mask = get_decoder_mask(tgt2.shape[1]).to(device)\n",
    "            \n",
    "#             print(tgt1.shape)\n",
    "#             print(memory.shape)\n",
    "#             print(t_mask.shape)\n",
    "#             print(s_mask.shape)\n",
    "#             print(tgt_mask.shape)\n",
    "            \n",
    "            pred = decoder(tgt1,memory,t_mask,s_mask,tgt_mask=tgt_mask)\n",
    "#             loss1 = criterion(pred,tgt2.to(device),num_classes=decoder.num_vocab,mask=loss_mask.to(device))\n",
    "            loss_mean = (criterion(pred.permute(0,2,1),tgt2)*loss_mask.to(device)).mean()\n",
    "#             loss_mean = loss1.mean()\n",
    "            \n",
    "            loss_mean.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "            torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "            en_optim.step()\n",
    "            de_optim.step()\n",
    "            \n",
    "            sum_loss += loss_mean.item()\n",
    "            \n",
    "            myplt.forward(loss_mean.item())\n",
    "         \n",
    "            if steps%per_n_steps == 0:\n",
    "                passtime = time.time() - start\n",
    "                min = passtime//60\n",
    "                s = passtime-min*60\n",
    "                print(f'time :{min} m {s} s, epoch: {epoch} steps: {steps} ;loss {loss_mean.item()}')\n",
    "        \n",
    "        torch.save(encoder.state_dict(),'TRANS05en_1.pth')\n",
    "        torch.save(decoder.state_dict(),'TRANS05de_1.pth')\n",
    "\n",
    "        print(' ',sum_loss)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3732d5aa-97ac-4074-bed2-31167d10a09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainfile = 'translation2019zh/translation2019zh_train.json'\n",
    "trainfile2 = 'cn-eng.txt'\n",
    "\n",
    "\n",
    "trainset = My_data(min_en_count=8,min_cn_count=0)\n",
    "# 3333trainset.do_all(trainfile, js=True)\n",
    "# raw_cn, raw_en = trainset.get_raw_data_cn_en(trainfile,js=True,divide=50,choose=1)\n",
    "# raw_cn2, raw_en2 = trainset.get_raw_data_cn_en(trainfile2,js=False)\n",
    "# raw_cn3 = raw_cn+raw_cn2\n",
    "# raw_en3 = raw_en+raw_en2\n",
    "# trainset.get_cn_en_stoi_itos(raw_cn3,raw_en3)\n",
    "\n",
    "\n",
    "cn_file = 'cn_vocab.txt'\n",
    "en_file = 'en_vocab.txt'\n",
    "trainset.get_from_vocab(cn_file,en_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22841bdc-6aba-42f0-acb5-1977a9ea611a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.03\n",
    "\n",
    "myplt = Myplot(50)\n",
    "\n",
    "# def __init__(self,num_vocab,d_model=512,nhead=2,num_layers=2,dropout=0.1):\n",
    "\n",
    "encoder = Encoder_2(trainset.num_cn_vocab, d_model=512, nhead=4, num_layers=4).to(device)\n",
    "decoder = Decoder_2(trainset.num_en_vocab, d_model=512, nhead=4, num_layers=4).to(device)\n",
    "\n",
    "en_optim = torch.optim.Adam(encoder.parameters(),lr=lr)\n",
    "de_optim = torch.optim.Adam(decoder.parameters(),lr=lr)\n",
    "\n",
    "en_scheduler = Warmup(en_optim,4000,512)\n",
    "de_scheduler = Warmup(de_optim,4000,512)\n",
    "\n",
    "# class Warmup:\n",
    "#     def __init__(self,optimizer, warmup_step,d_model,step_size=1,last_epoch=-1,verbose=False):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cef3cab2-b96f-4c5a-a9f4-badcf075566e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder_2(\n",
       "  (embedding): Embedding(25769, 512)\n",
       "  (MH): TransformerDecoderLayer(\n",
       "    (self_attn): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "    )\n",
       "    (multihead_attn): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "    )\n",
       "    (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout1): Dropout(p=0.1, inplace=False)\n",
       "    (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    (dropout3): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (all_MH): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dense): Linear(in_features=512, out_features=25769, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#模型初始化\n",
    "def weights_init(m):\n",
    "    if isinstance(m,(nn.Linear)):\n",
    "#         nn.init.xavier_normal_(m.weight)\n",
    "        nn.init.constant_(m.bias,0.0)\n",
    "        nn.init.orthogonal_(m.weight)\n",
    "        #正交初始化\n",
    "def weights_init2(m):\n",
    "    if isinstance(m,(nn.Linear)):\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        nn.init.constant_(m.bias,0.0)\n",
    "    \n",
    "\n",
    "encoder.apply(weights_init2)\n",
    "decoder.apply(weights_init2)\n",
    "# # attentioner.apply(weights_init2)\n",
    "# enc = torch.load('TRANS03en.pth')\n",
    "# dec = torch.load('TRANS03de.pth')\n",
    "# encoder.load_state_dict(torch.load('TRANS07en.pth',map_location=device))\n",
    "# decoder.load_state_dict(torch.load('TRANS07de.pth',map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df59ddf4-af74-4156-ae38-f52ca961c67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd9c9342-52fb-420b-aac4-6a5026b5b1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "clip = 5\n",
    "teacher_force_ratio = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d12d3402-0918-4ebe-adb1-bf4f4db89959",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1\n",
    "\n",
    "en_optim = torch.optim.Adam(encoder.parameters(),lr=lr)\n",
    "de_optim = torch.optim.Adam(decoder.parameters(),lr=lr)\n",
    "\n",
    "en_scheduler = Warmup(en_optim,8000,512)\n",
    "de_scheduler = Warmup(de_optim,8000,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2ab1e51-3b4a-4d86-b0ec-b1e7e0847433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw_cn, raw_en = trainset.get_raw_data_cn_en(trainfile2,js=False)\n",
    "# trainset.get_data(raw_cn,raw_en)\n",
    "\n",
    "# # raw_cn, raw_en = trainset.get_raw_data_cn_en(trainfile,js=True,divide=100,choose=1)\n",
    "# file3 = 't22'\n",
    "# raw_cn, raw_en = trainset.get_raw_data_cn_en(file3,js=False)\n",
    "# trainset.append_data(raw_cn,raw_en)\n",
    "len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32d01e36-3d30-4320-9e78-bbafa1017031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 256\n",
    "# train_iter = Data.DataLoader(trainset,batch_size,shuffle=True,collate_fn=batchify,num_workers=8)\n",
    "# train(num_epochs,encoder,decoder,en_optim,de_optim,en_scheduler,\n",
    "#       de_scheduler,criterion,train_iter,myplt,teacher_force_ratio,clip=clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41837f75-7f34-40d2-b9fb-14fbcf9b8c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "####train 2v\n",
    "import time \n",
    "    \n",
    "start = time.time()\n",
    "per_n_steps = 100\n",
    "steps = 0\n",
    "arang_list = torch.arange(512)\n",
    "ones_list = torch.ones(512)\n",
    "    \n",
    "encoder.train()\n",
    "decoder.train()\n",
    "    \n",
    "for epoch in range(1,num_epochs+1):\n",
    "    \n",
    "    if epoch%5 == 0 or epoch==1:\n",
    "#         raw_cn, raw_en = trainset.get_raw_data_cn_en(trainfile2,js=False)\n",
    "#         trainset.get_data(raw_cn,raw_en)\n",
    "        raw_cn, raw_en = trainset.get_raw_data_cn_en(trainfile,js=True,divide=30,choose=random.randint(1,29))\n",
    "        trainset.get_data(raw_cn,raw_en)\n",
    "        \n",
    "        batch_size = 256\n",
    "        train_iter = Data.DataLoader(trainset,batch_size,shuffle=True,collate_fn=batchify,num_workers=8)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.empty_cache()\n",
    "        \n",
    "    sum_loss = 0\n",
    "    k = 0\n",
    "        \n",
    "    for src, tgt1, tgt2, s_mask, t_mask, loss_mask in train_iter:\n",
    "            \n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.empty_cache()\n",
    "            \n",
    "        steps += 1\n",
    "            \n",
    "        src = src.to(device)\n",
    "        tgt1 = tgt1.to(device)\n",
    "        tgt2 = tgt2.to(device)\n",
    "        s_mask = s_mask.to(device)\n",
    "        t_mask = t_mask.to(device)\n",
    "        \n",
    "            #else do tecacher_forcing\n",
    "        changes = random.choices(arang_list[1:tgt1.shape[-1]],ones_list[1:tgt1.shape[-1]],k=int(tgt1.shape[-1]*(1-teacher_force_ratio)))\n",
    "        for idx in changes:\n",
    "            tgt1[:,idx] = random.randint(3,decoder.num_vocab-1)\n",
    "                    \n",
    "                \n",
    "            \n",
    "        en_scheduler.step()\n",
    "        de_scheduler.step()\n",
    "        en_optim.zero_grad()\n",
    "        de_optim.zero_grad()\n",
    "        memory = encoder(src,s_mask)\n",
    "        tgt_mask = get_decoder_mask(tgt2.shape[1]).to(device)\n",
    "            \n",
    "        pred = decoder(tgt1,memory,t_mask,s_mask,tgt_mask=tgt_mask)\n",
    "#             loss1 = criterion(pred,tgt2.to(device),num_classes=decoder.num_vocab,mask=loss_mask.to(device))\n",
    "        loss_mean = (criterion(pred.permute(0,2,1),tgt2)*loss_mask.to(device)).mean()\n",
    "#             loss_mean = loss1.mean()\n",
    "            \n",
    "        loss_mean.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "        torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "        en_optim.step()\n",
    "        de_optim.step()\n",
    "            \n",
    "        sum_loss += loss_mean.item()\n",
    "            \n",
    "        myplt.forward(loss_mean.item())\n",
    "         \n",
    "        if steps%per_n_steps == 0:\n",
    "            passtime = time.time() - start\n",
    "            mins = passtime//60\n",
    "            s = passtime-mins*60\n",
    "            print(f'time :{mins} m {s} s, epoch: {epoch} steps: {steps} ;loss {loss_mean.item()}')\n",
    "        \n",
    "    torch.save(encoder.state_dict(),'TRANS05en_1.pth')\n",
    "    torch.save(decoder.state_dict(),'TRANS05de_1.pth')\n",
    "\n",
    "    print(' ',sum_loss)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a07d08-778d-43b7-9769-49c8cb804334",
   "metadata": {},
   "outputs": [],
   "source": [
    "myplt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
